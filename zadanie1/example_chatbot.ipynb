{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-2.8.1-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting anyio<5,>=3.5.0 (from openai)\n",
            "  Downloading anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting distro<2,>=1.7.0 (from openai)\n",
            "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.10.0 (from openai)\n",
            "  Downloading jiter-0.12.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting pydantic<3,>=1.9.0 (from openai)\n",
            "  Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
            "Collecting sniffio (from openai)\n",
            "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting tqdm>4 (from openai)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting typing-extensions<5,>=4.11 (from openai)\n",
            "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai)\n",
            "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting certifi (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.41.5 (from pydantic<3,>=1.9.0->openai)\n",
            "  Downloading pydantic_core-2.41.5-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspection>=0.4.2 (from pydantic<3,>=1.9.0->openai)\n",
            "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Downloading openai-2.8.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anyio-4.11.0-py3-none-any.whl (109 kB)\n",
            "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
            "Downloading jiter-0.12.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (361 kB)\n",
            "Downloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
            "Downloading pydantic_core-2.41.5-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m103.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
            "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
            "Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
            "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: typing-extensions, tqdm, sniffio, jiter, idna, h11, distro, certifi, annotated-types, typing-inspection, pydantic-core, httpcore, anyio, pydantic, httpx, openai\n",
            "Successfully installed annotated-types-0.7.0 anyio-4.11.0 certifi-2025.11.12 distro-1.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.11 jiter-0.12.0 openai-2.8.1 pydantic-2.12.5 pydantic-core-2.41.5 sniffio-1.3.1 tqdm-4.67.1 typing-extensions-4.15.0 typing-inspection-0.4.2\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
            "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.2.1\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# OpenAI Settings\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "APIKey = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "import openai\n",
        "openai.api_key = APIKey\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "#declare connection with OpenAI\n",
        "from openai import OpenAI\n",
        "client = OpenAI(\n",
        "    api_key=APIKey,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "system_prompt = \"Wpisz prompt systemowy tutaj\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "assistant = \"\"\"Tutaj odpowiedzi na poprzednie pytania\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "user_query = \"Kto jest prezydentem Polski\"\n",
        "user_previous_query = \"Tutaj poprzednie pytania\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Kto jest prezydentem Polski'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "user_query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages=[\n",
        "            {\"role\": \"developer\", \"content\": system_prompt},        \n",
        "            {\"role\": \"user\", \"content\": user_previous_query},\n",
        "            {\"role\": \"assistant\", \"content\": assistant},\n",
        "            {\"role\": \"user\", \"content\": user_query}\n",
        "    \n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'role': 'developer', 'content': 'Wpisz prompt systemowy tutaj'},\n",
              " {'role': 'user', 'content': 'Tutaj poprzednie pytania'},\n",
              " {'role': 'assistant', 'content': 'Tutaj odpowiedzi na poprzednie pytania\\n'},\n",
              " {'role': 'user', 'content': 'Kto jest prezydentem Polski'}]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = client.responses.create(\n",
        "    input=messages,\n",
        "    model=\"gpt-4o\",\n",
        "    temperature=1\n",
        "    \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prezydentem Polski jest Andrzej Duda.\n"
          ]
        }
      ],
      "source": [
        "print(response.output_text.strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response(id='resp_08fac9013c9f59b8006928a267a260819092909375a8576f15', created_at=1764270695.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4o-2024-08-06', object='response', output=[ResponseOutputMessage(id='msg_08fac9013c9f59b8006928a268441481908286d99f9ed1d57f', content=[ResponseOutputText(annotations=[], text='Prezydentem Polski jest Andrzej Duda.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, prompt_cache_retention=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=52, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=12, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=64), user=None, billing={'payer': 'developer'}, store=True)\n"
          ]
        }
      ],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Interfejs użytkownika"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'ipywidgets'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mipywidgets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwidgets\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'ipywidgets'"
          ]
        }
      ],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "from datetime import datetime\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"developer\", \"content\": system_prompt}\n",
        "   ]\n",
        "\n",
        "# GUI\n",
        "user_input = widgets.Text(placeholder=\"Pytanie...\")\n",
        "send_button = widgets.Button(description=\"Wyślij\")\n",
        "output_area = widgets.Output()\n",
        "\n",
        "def on_send_click(b):\n",
        "    # odczytujemy pytanie użytkownika\n",
        "    user_query = user_input.value.strip()\n",
        "    #Jeśli jest puste to nic nie robimy\n",
        "    if not user_query:\n",
        "        return\n",
        "\n",
        "    #wypisujemy pytanie użytkownika na ekranie\n",
        "    with output_area:\n",
        "        display(widgets.HTML(f'<b>Ty:</b> {user_query}'))\n",
        "\n",
        "    #odczytujemy bieżącą godzinę\n",
        "    global current_time \n",
        "    current_time = f\"Aktualna data i godzina: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
        "\n",
        "    # Dopisujemy pytanie użytkownika do komunikatu\n",
        "    messages.append({\"role\": \"user\", \"content\": user_query})\n",
        "    \n",
        "    # komunikacja z API\n",
        "    response = client.responses.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        input=messages+[{\"role\": \"developer\", \"content\": current_time}],\n",
        "        temperature=0.5\n",
        "    )\n",
        "    \n",
        "    assistant_reply = response.output_text.strip()\n",
        "    \n",
        "    # Dopisz historię komunikatów\n",
        "    messages.append({\"role\": \"assistant\", \"content\": assistant_reply})\n",
        "    \n",
        "    # Wyświetl odpowiedź użytkownika\n",
        "    with output_area:\n",
        "        display(widgets.HTML(f'<b>Asystent:</b> {assistant_reply}'))\n",
        "    \n",
        "    user_input.value = \"\"  # wyczyść pole\n",
        "\n",
        "# assignment of send function\n",
        "send_button.on_click(on_send_click)\n",
        "\n",
        "# Wyświetl interfejs użytkownika\n",
        "display(user_input, send_button, output_area)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
